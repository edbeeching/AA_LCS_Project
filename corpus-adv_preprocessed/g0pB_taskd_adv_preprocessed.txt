bayes theorem relates the conditional and marginal probabilities of
two random events. for example, a person may be seen to have certain
medical symptoms bayes theorem can then be used to compute the
probability that, given that observation, the proposed diagnosis is
the right one.
bayes theorem forms a relationship between the probabilities xcof
events a and b. intuitively, bayes theorem in this form describes the
way in which ones recognition of a are updated by having observed
b.
pa | b = pb | a pa  pb
pa|b is the conditional probability of a given b. it is derived from or depends upon the specified value of b, therefore it is also known as the posterior probability.
pb|a is the conditional probability of b given a.
pa is the prior probability a. it doesnt take into account any information about b, so it is prior.
pb is the prior or marginal probability of b, and acts to normalise the probability.
to derive the theorem, we begin with the definition of conditional
probability. by combining and re-arranging these two equations for a
and b, we get a the lemma called product rule for
probabilities. provided that pb is not a zero, dividing both sides
by pb renders us with bayes theorem.
